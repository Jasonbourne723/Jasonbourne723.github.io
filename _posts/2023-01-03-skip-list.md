---
title: 数据结构与算法：跳表
date: 2023-01-03 10:12:00 +0800
categories: [4.数据结构与算法]
tags: [数据结构与算法]
---


> 跳表（skiplist）本质上是一种查找结构，用于解决算法中的查找问题（Searching），即根据给定的key，快速查到它所在的位置（或者对应的value）。

## 实现原理

对于一个单链表来讲，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率就会很低，时间复杂度会很高，是 O(n)。假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图：

![](/assets/img/skip-list/001.png)

这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半（上图中是7, 19, 26）。现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的：

![](/assets/img/skip-list/002.png)

23首先和7比较，再和19比较，比它们都大，继续向后比较。但23和26比较的时候，比26要小，因此回到下面的链表（原链表），与22比较。23比22要大，沿下面的指针继续向后和26比较。23比26小，说明待查数据23在原链表中不存在，而且它的插入位置应该在22和26之间。在这个查找过程中，由于新增加的指针，我们不再需要与链表中每个节点逐个进行比较了。需要比较的节点数大概只有原来的一半。利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。如下图：

![](/assets/img/skip-list/003.png)

在这个新的三层链表结构上，如果我们还是查找23，那么沿着最上层链表首先要比较的是19，发现23比19大，接下来我们就知道只需要到19的后面去继续查找，从而一下子跳过了19前面的所有节点。可以想象，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。skiplist正是受这种多层链表的想法的启发而设计出来的。实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。

skiplist为了避免这一问题，它不要求上下相邻两层链表之间的节点个数有严格的对应关系，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程：

![](/assets/img/skip-list/004.png)

从上面skiplist的创建和插入过程可以看出，每一个节点的层数（level）是随机出来的，而且新插入一个节点不会影响其它节点的层数。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是skiplist的一个很重要的特性，这让它在插入性能上明显优于平衡树的方案。

## 代码示例

```
public class SkipList
{
    private const int _maxLevel = 5;
    private Random _random = new Random();
    private Node _head;
    private int _level = 1;

    public SkipList()
    {
        _head = new Node(_maxLevel);
    }
    public void Insert(int data)
    {
        var level = _head.forward[0] == null ? 1 : RandomLevel();
        if (level > _level)
        {
            level = ++_level > _maxLevel ? _level-- : _level;
        }

        var newNode = new Node(level);
        newNode.Data = data;
        var node = _head;
        for (int i = _level - 1; i >= 0; i--)
        {
            while (node.forward[i] != null && node.forward[i].Data < data)
            {
                node = node.forward[i];
            }
            if (level > i)
            {
                if (node.forward[i] == null)
                {
                    node.forward[i] = newNode;
                }
                else
                {
                    var next = node.forward[i];
                    node.forward[i] = newNode;
                    newNode.forward[i] = next;
                }
            }
        }
    }
    public void Search(int data)
    {
        var node = _head;
        for (int i = _level - 1; i >= 0; i--)
        {
            while (node.forward[i] != null && node.forward[i].Data <= data)
            {
                if (node.forward[i].Data == data)
                {
                    Console.WriteLine(node.forward[i].Data);
                    return;
                }
                else
                {
                    node = node.forward[i];
                    Console.WriteLine(node.Data);
                }
            }
        }
    }
    /**
* 打印所有数据
*/
    public void Print()
    {
        Node p = _head;
        Node[] c = p.forward;
        Node[] d = c;
        int maxLevel = c.Length;
        for (int i = _level - 1; i >= 0; i--)
        {
            do
            {
                Console.Write((d[i] == null ? null : d[i].Data) + "--");
            } while (d[i] != null && (d = d[i].forward)[i] != null);
            Console.WriteLine("");
            d = c;
        }
    }
    private int RandomLevel()
    {
        var level = 1;
        for (int i = 0; i < _maxLevel; i++)
        {
            if (_random.Next() % 2 == 1)
            {
                level++;
            }
            else
            {
                break;
            }
        }
        return level;
    }
    public class Node
    {
        private readonly int _level;
        public Node[] forward;
        public Node(int level)
        {
            _level = level;
            forward = new Node[level];
        }
        public int? Data { get; set; }
    }
}
```

## skiplist与平衡树、哈希表的比较

1. skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
2. 在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。
3. 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。
4. 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。
5. 查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。
6. 从算法实现难度上来比较，skiplist比平衡树要简单得多。